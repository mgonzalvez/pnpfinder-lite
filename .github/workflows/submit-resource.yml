name: Sync resources.csv from Google Sheets (direct commit)

on:
  schedule:
    - cron: "*/30 * * * *"    # every 30 minutes (UTC)
  workflow_dispatch:          # allow manual runs

permissions:
  contents: write

env:
  SHEETS_CSV_URL: "https://docs.google.com/spreadsheets/d/e/2PACX-1vTzMDg28m0vmjU9CKRH6a02NWp6Y__3Ysr7VnLG5zdmB6-mhFmomCPJa6Zs0FLkPHXaQx34oQmCoH7G/pub?gid=1706128299&single=true&output=csv"
  # Canonical header order your site expects for resources
  REQUIRED_HEADER: "Category,Title,Description,Link,Image,Creator"

jobs:
  sync:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout full history
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Install tools
        run: |
          sudo apt-get update
          sudo apt-get install -y dos2unix python3

      - name: Download published CSV
        run: |
          mkdir -p data
          curl -sSL "$SHEETS_CSV_URL" -o data/resources.source.csv
          dos2unix data/resources.source.csv || true
          # strip UTF-8 BOM if present
          sed -i '1s/^\xEF\xBB\xBF//' data/resources.source.csv
          echo "SOURCE header:"
          head -n 1 data/resources.source.csv

      - name: Normalize headers and column order
        run: |
          python3 - << 'PY'
          import csv, re

          SRC = "data/resources.source.csv"
          OUT = "data/resources.normalized.csv"

          # Canonical order (what your site expects)
          CANON = ["Category","Title","Description","Link","Image","Creator"]

          # Normalize key (case/space/punct insensitive)
          def norm(s): return re.sub(r"[^a-z0-9]+"," ", (s or "").strip().lower()).strip()

          # Your sheet headers are all caps: CATEGORY, TITLE, CREATOR, DESCRIPTION, LINK, IMAGE
          # Also support common aliases (URL/Website/Thumb/etc.)
          ALIASES = {
            norm("CATEGORY"): "Category",
            norm("TITLE"): "Title",
            norm("DESCRIPTION"): "Description",
            norm("LINK"): "Link",
            norm("URL"): "Link",
            norm("WEBSITE"): "Link",
            norm("IMAGE"): "Image",
            norm("IMG"): "Image",
            norm("THUMBNAIL"): "Image",
            norm("THUMB"): "Image",
            norm("COVER"): "Image",
            norm("CREATOR"): "Creator",
            norm("AUTHOR"): "Creator",
            norm("CHANNEL"): "Creator",
            # ignore extras if present
            norm("DATE ADDED"): None,
            norm("NOTES"): None,
          }

          with open(SRC, newline="", encoding="utf-8") as f:
            r = csv.DictReader(f)
            src_fields = r.fieldnames or []

            # Map incoming → canonical
            keymap = {}
            canon_norm = {norm(c): c for c in CANON}
            for k in src_fields:
              nk = norm(k)
              if nk in ALIASES and ALIASES[nk] is not None:
                keymap[k] = ALIASES[nk]
              elif nk in canon_norm:
                keymap[k] = canon_norm[nk]   # already canonical in meaning
              else:
                keymap[k] = None             # unknown column → ignore

            rows = list(r)

          # Write normalized CSV in canonical order
          with open(OUT, "w", newline="", encoding="utf-8") as g:
            w = csv.DictWriter(g, fieldnames=CANON)
            w.writeheader()
            for row in rows:
              outrow = {col: "" for col in CANON}
              for k, v in row.items():
                ck = keymap.get(k)
                if ck in outrow:
                  outrow[ck] = v
              w.writerow(outrow)
          PY
          echo "NORMALIZED header:"
          head -n 1 data/resources.normalized.csv
          echo "Rows:"
          wc -l data/resources.normalized.csv

      - name: Validate normalized CSV
        run: |
          ACT="$(head -n 1 data/resources.normalized.csv | tr -d '\r')"
          echo "Normalized header: $ACT"
          if [ "$ACT" != "$REQUIRED_HEADER" ]; then
            echo "Normalized header mismatch."
            exit 1
          fi
          ROWS=$(wc -l < data/resources.normalized.csv || echo 0)
          if [ "$ROWS" -lt 2 ]; then
            echo "No data rows after normalization."
            exit 1
          fi

      - name: Detect changes
        id: diff
        run: |
          if [ ! -f data/resources.csv ]; then
            echo "changed=true" >> $GITHUB_OUTPUT
          else:
            if diff -q data/resources.csv data/resources.normalized.csv >/dev/null 2>&1; then
              echo "changed=false" >> $GITHUB_OUTPUT
            else
              echo "changed=true" >> $GITHUB_OUTPUT
            fi
          fi

      - name: Commit & push (direct)
        if: steps.diff.outputs.changed == 'true'
        run: |
          mv data/resources.normalized.csv data/resources.csv
          git config --global user.name  "pnpfinder-bot"
          git config --global user.email "bot@users.noreply.github.com"
          git config --global --add safe.directory "$GITHUB_WORKSPACE"
          git add data/resources.csv
          git fetch origin main
          git checkout main
          git pull --rebase origin main || true
          if git diff --cached --quiet; then
            echo "Nothing to commit."
            exit 0
          fi
          git commit -m "chore: sync resources.csv from Google Sheets (normalized)"
          git push origin main
